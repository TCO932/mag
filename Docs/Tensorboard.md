### Общие принципы чтения графиков в TensorBoard

1.  **Ось X (горизонтальная): `Step` или `Timestep`**. Это почти всегда общее количество шагов взаимодействия агента со средой. Это главный показатель прогресса обучения. 1 шаг = 1 вызов `env.step()`.
2.  **Ось Y (вертикальная): `Value`**. Это значение конкретной метрики в данный момент времени (на данном шаге).
3.  **Сглаживание (Smoothing)**. В левой панели TensorBoard есть ползунок "Smoothing". Он очень важен! Графики в RL часто бывают "шумными" (сильно колеблются). Сглаживание помогает увидеть основной тренд, убирая мелкие флуктуации. Не бойтесь выкручивать его на 0.6-0.9, чтобы лучше видеть общую картину.

---

### Разбор конкретных метрик

Ниже разберем каждую метрику: что она означает, какой график считать "хорошим", а какой — "плохим".

#### 1. `ep_rew_mean` (Mean Episode Reward / Средняя награда за эпизод)

*   **Что это?** **Самый важный график.** Он показывает среднюю суммарную награду, которую агент получил за последние N эпизодов (обычно N=100). Эпизод — это одна полная "игра" от начала до конца.
*   **Как читать?** По оси Y — средняя награда. По оси X — шаги обучения.
*   **✅ Хороший тренд:** **Уверенный рост вверх.** Это означает, что агент учится выполнять задачу лучше и со временем получает все больше награды. В конце обучения график может выйти на плато — это значит, что агент достиг своего максимального уровня производительности (или "сошелся").
*   **❌ Плохие знаки:**
    *   **Горизонтальная линия (стагнация):** Агент не учится. Что-то не так с гиперпараметрами, функцией награды или самой средой.
    *   **Падение вниз:** Агент "разучивается". Такое бывает при нестабильном обучении.
    *   **Очень сильные колебания (даже со сглаживанием):** Обучение нестабильно. Возможно, слишком высокий `learning_rate`.



#### 2. `ep_len_mean` (Mean Episode Length / Средняя длина эпизода)

*   **Что это?** Среднее количество шагов (действий) в последних N эпизодах.
*   **Как читать?** Анализировать этот график нужно **вместе с `ep_rew_mean`**. Его "хорошесть" зависит от задачи.
*   **✅ Хороший тренд:**
    *   **Для задач на "выживание"** (например, CartPole, LunarLander): График должен **расти** вместе с наградой. Чем дольше агент "живет", тем лучше.
    *   **Для задач на достижение цели** (например, добраться до точки): График может **уменьшаться**. Это значит, что агент находит более короткий и эффективный путь к цели.
*   **❌ Плохие знаки:**
    *   В задаче на выживание длина эпизода падает — агент начал быстро проигрывать.
    *   Резкие и необъяснимые скачки.

---

### Метрики производительности и диагностики

Эти графики показывают "внутреннюю кухню" обучения. Они помогают понять, *почему* `ep_rew_mean` ведет себя так, а не иначе.

#### 3. `actor_loss` (или `policy_loss`) и `critic_loss` (или `value_loss`)

*   **Что это?** Это функции потерь для нейронных сетей "Актера" и "Критика".
    *   **Критик (Critic)** учится предсказывать будущую награду (насколько "хороша" текущая ситуация). `critic_loss` показывает ошибку в этом предсказании.
    *   **Актер (Actor)** учится выбирать действия. `actor_loss` показывает, насколько сильно обновляется политика на каждом шаге.
*   **Как читать?**
    *   **`critic_loss`**:
        *   **✅ Хороший тренд:** Должен **уменьшаться и стабилизироваться** на каком-то низком уровне. Это значит, что критик научился хорошо оценивать состояния.
        *   **❌ Плохие знаки:** **Резкий рост (взрыв) или сильные колебания.** Это главный признак нестабильности обучения. Частая причина — слишком высокий `learning_rate` или ненормализованные награды/наблюдения.
    *   **`actor_loss`**:
        *   **✅ Хороший тренд:** Этот график более сложный. Он **не обязан стремиться к нулю**. Главное, чтобы он оставался **стабильным в каком-то диапазоне** и не "взрывался". Если `actor_loss` стабилен, а `ep_rew_mean` растет — все отлично.
        *   **❌ Плохие знаки:** **Резкий рост или падение в большие отрицательные значения.** Указывает на слишком резкие обновления политики, что ведет к нестабильности.



#### 4. `ent_coef` (Entropy Coefficient) и `ent_coef_loss`

Эти метрики относятся к алгоритмам, использующим энтропию для поощрения исследования (например, SAC, A2C, PPO).

*   **Что такое энтропия?** Мера "случайности" или "неуверенности" в действиях агента.
    *   Высокая энтропия = агент пробует много разных действий (**исследование / exploration**).
    *   Низкая энтропия = агент уверен в своих действиях и выбирает лучшее из них (**эксплуатация / exploitation**).
*   **`ent_coef` (Коэффициент энтропии)**
    *   **Что это?** Вес, с которым энтропия добавляется к функции потерь. В современных алгоритмах (как SAC) этот коэффициент настраивается автоматически.
    *   **✅ Хороший тренд (для SAC):** График должен плавно **снижаться**. В начале обучения агент много исследует (высокий `ent_coef`), а по мере нахождения хороших стратегий начинает их эксплуатировать (`ent_coef` падает).
    *   **❌ Плохие знаки:**
        *   Застрял на высоком уровне: агент не перестает исследовать и не может найти оптимальную политику.
        *   Слишком быстро упал до нуля: агент перестал исследовать слишком рано и мог застрять в локальном оптимуме.
*   **`ent_coef_loss`**
    *   **Что это?** Функция потерь для самого `ent_coef` (в SAC). Показывает, насколько текущая энтропия далека от целевой.
    *   **✅ Хороший тренд:** Должен **сойтись к нулю или очень маленькому значению**. Это значит, что `ent_coef` стабилизировался.

#### 5. `learning_rate` (Скорость обучения)

*   **Что это?** Показывает текущее значение скорости обучения. Это не результат, а скорее визуализация ваших настроек.
*   **Как читать?**
    *   Если вы не используете расписание (scheduler), это будет **горизонтальная линия**.
    *   Если вы используете расписание (например, линейное уменьшение), то график будет **идти вниз** со временем. Это полезно, чтобы убедиться, что ваше расписание работает как задумано.

#### 6. `fps` (Frames Per Second)

*   **Что это?** Количество шагов среды (фреймов), обрабатываемых в секунду.
*   **Как читать?** Это показатель **скорости вычислений**, а не качества обучения.
*   **✅ Хороший тренд:** **Как можно выше и стабильнее.** Чем выше FPS, тем быстрее проходят ваши эксперименты.
*   **❌ Плохие знаки:** Низкое значение. Может указывать на то, что ваша среда очень "тяжелая", или что модель работает на CPU вместо GPU.

---

### Краткая сводка и практические советы

| Метрика | Что измеряет | ✅ Идеальный тренд | ❌ На что обратить внимание | Что делать при проблемах |
| :--- | :--- | :--- | :--- | :--- |
| **`ep_rew_mean`** | **Производительность агента** | **Растет и стабилизируется** | Стагнация, падение | Главный индикатор. Если он плохой, смотри на остальные графики. |
| `ep_len_mean` | Длительность эпизода | Растет (выживание) или падает (достижение цели) | Не соответствует цели задачи | Анализировать вместе с `ep_rew_mean`. |
| `critic_loss` | Ошибка предсказания награды | Падает и стабилизируется | Взрыв, сильные колебания | Понизить `learning_rate`, проверить нормализацию наград. |
| `actor_loss` | Изменение политики | Стабилен (не обязательно к нулю) | Взрыв, сильные колебания | Понизить `learning_rate`, использовать `gradient clipping`. |
| `ent_coef` (SAC) | Баланс исследование/эксплуатация | Плавно снижается | Застрял на высоком/низком уровне | Настроить `target_entropy` (если возможно). |
| `learning_rate` | Скорость обновления весов | Показывает ваше расписание | (Информационный) | - |
| `fps` | Скорость вычислений | Высокий и стабильный | Низкое значение | Проверить узкие места (CPU/GPU, сложность среды). |

**Главный совет:** Смотрите на графики **в комплексе**. `ep_rew_mean` — это ваша цель. Остальные графики — это диагностические инструменты, которые помогают понять, почему вы достигаете (или не достигаете) этой цели. Удачи в обучении ваших агентов